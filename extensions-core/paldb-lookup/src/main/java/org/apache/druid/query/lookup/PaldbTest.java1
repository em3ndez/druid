/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

package org.apache.druid.query.lookup;

import com.linkedin.paldb.api.PalDB;
import com.linkedin.paldb.api.StoreWriter;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.util.ArrayList;
import java.util.HashSet;
import java.util.List;
import java.util.Set;
import java.util.StringTokenizer;

public class PaldbTest
{

  public static void main(String args[]) throws IOException
  {

    StringTokenizer st;
    BufferedReader TSVFile = new BufferedReader(new FileReader(
        "/Users/surekha/imply/lookup/walmart-data/item_dim_mini.tsv"));
    StoreWriter writer = PalDB.createWriter(new File("store.paldb"));
    String dataRow = TSVFile.readLine(); // Read first line.
    int count = 0;
    //Map<String,String> map = new HashMap<>();
    Set<String> set = new HashSet<>();
    while (dataRow != null) {
      st = new StringTokenizer(dataRow, "\t");
      List<String> dataArray = new ArrayList<String>();
      while (st.hasMoreElements()) {
        dataArray.add(st.nextElement().toString());
      }
      String key = dataArray.get(0);

      //StringBuilder sb = new StringBuilder();
      String[] arr = new String[dataArray.size()];
      for (int i = 0; i < dataArray.size() ; i++) {
        arr[i] = dataArray.get(i);
      //sb.append(item).append(" ");
      //System.out.print(item + "  ");
      }
      //String value = sb.toString();
      /*Long value = 0L;

        String data = dataArray.get(18);
        if (("NULL").equals(data)) {
          value = 0L;
        } else {
          value = Long.valueOf(data);
        }*/

      if (set.contains(key)) {
        //String oldVal = map.get(key);
        count++;
        //System.out.println(key);
        //System.out.print(" "+ oldVal + " ");
        //System.out.print(" "+value + " ");
      } else {
        if (!(Long.valueOf(key) < 0)) {
          writer.put(key, arr);
        }
        set.add(key);
      }

      //System.out.println(); // Print the data line.
      dataRow = TSVFile.readLine(); // Read next line of data.
    }
    //System.out.println("count=" + count);
    writer.close();
    TSVFile.close();

   /* File file = new File("/Users/surekha/imply/lookup/examples/paldb/channel");

    StoreWriter writer = PalDB.createWriter(new File("store.paldb"));
    BufferedReader reader = new BufferedReader(new FileReader(file));
    String currentLine = reader.readLine();
    while (currentLine != null) {
      String key = currentLine;
      String value = currentLine + "-lookup";
      writer.put(key, value);
      currentLine = reader.readLine();
    }

    reader.close();
    writer.close();*/
/*
    StoreWriter writer = PalDB.createWriter(new File("store.paldb"));
    for(int i =0; i < 10000000 ; i++){
      String key = "key-" + i;
      String value = "val-"+i;
      writer.put(key, value);
    }
    writer.close();


    StoreReader reader = PalDB.createReader(new File("store.paldb"));
    Iterable<Map.Entry<String, String>> iterable = reader.iterable();
    for (Map.Entry<String, String> entry : iterable) {
      Object key = entry.getKey();
      Object value = entry.getValue();
      //System.out.println("key:" + key + " value:" + value.toString());
    }
    reader.close();*/

  }
}

